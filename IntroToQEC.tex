% ##QuantumErrorCorrection
\documentclass[10pt,a4paper, english]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{babel}
\usepackage[cm]{fullpage}
\usepackage{float}
\usepackage{graphicx}
\usepackage{helvet}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{nicefrac}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{placeins}
\usepackage{verbatim}
\usepackage{xcolor}
\definecolor{gr}{gray}{0.9}
\renewcommand{\familydefault}{\sfdefault}
\title{Intro to Quantum Error Correction}
\author{Ben Criger}
\date{\today}
\input{Qcircuit.tex}
\input{bencommands.tex}
\newlength\figureheight
\newlength\figurewidth
\setlength\figureheight{7cm}
\setlength\figurewidth{12cm}

\providecommand{\cnot}{\textsc{cnot}}
\providecommand{\volts}{\, \textrm{V}}

\usetikzlibrary{decorations.pathreplacing,decorations.pathmorphing}

\begin{document}
\maketitle
\section{Introduction}
The purpose of this note is to help introduce quantum error correction [QEC] and (especially) fault-tolerance to people who are not familiar with quantum mechanics, or quantum computing, such as:
\begin{itemize}
\item undergraduates,
\item electrical/computer/software engineers,
\item experimental physicists now trying to implement QEC, who have missed such an introduction.
\end{itemize}
My goals in writing this note are:
\begin{itemize}
\item to keep it short, at the cost of completeness,
\item to refer to longer/superior works where possible (often),
\item to frequently compare ``scary quantum'' processes with their classical equivalents, to help de-mystify QEC.
\end{itemize}
[Insert usual caveat about imprecise notation, i.e.: these notes are free, and you get what you pay for.]

I begin in the following section with an explanation of why error correction is necessary, moving on to describe the difference between error-correction and fault-tolerance, before moving on to the most popular elements of QEC theory (stabilizer codes $\mapsto$ CSS codes $\mapsto$ homological codes $\mapsto$ the surface code). 
\section{Why Error Correction?}
If you meet a software engineer in the street, the need for error correction may not be obvious. 
In the life of a computer programmer, errors are things caused exclusively by people, and careful thinking and good practices are required to prevent, detect and correct them. 
[Maybe there's a repetition code at work here, especially with \texttt{diff}, but that is an analogy for another day.]
However, if you scratch the surface, you find instances of error correction and even (what I'm going to call) fault-tolerance at work. 

Take, for example, satellite/spacecraft communications. 
These spacecraft are very far away, and there are bits that don't make it between the spacecraft and the ground station. 
Actually, that example is too far outside our daily experience to take, so let's take flash drives, AKA USB keys.
The job of these drives is to store bits ($0$'s and $1$'s), which they manage to do most of the time.
However, one bit in every $10^{4\text{--}9}$ is randomly flipped, which in the worst case scenario would lead to an ASCII typo per page of text [or something].

To compensate for this, the USB key records the information redundantly, using more bits than are strictly necessary.
When reading, the CPU can then check that different decodings of the redundant information are consistent, and if they're not, can infer a decoding that's likely to be correct. 
The fact that the CPU is not itself (assumed to be) error-prone is a great boon to us in reading USB keys, otherwise we couldn't trust that any decoding was correct. 

There's a reason that CPUs are not considered noisy, by the way.
Transistor-transistor logic (TTL for short) defines a standard voltage for its $0$ and $1$ states, usually $0 \volts$ and  $5 \volts$, respectively.
These circuits can be designed to output $0 \volts$ for any input voltage between $0 \volts$ and $0.4 \volts$, likewise to output $5 \volts$ whenever a voltage of $2.6 \volts$ or higher is input. 
This is a (very powerful) error correction mechanism. 
If noise spreads voltages out according to some unimodal distribution, we can tighten that distribution at every TTL element, paying only a small energy cost to do so. 
In theory, we could also design an element which outputs a third value whenever the input voltage doesn't correspond to a logical $0$ or $1$, so that we can detect errors. 
In practice, we would just increase the supply voltage until we don't have to worry. 

The availability of reliable components which can be used to store and process classical information is a great benefit to computer engineers.
In the following sections, we'll see which of these properties can also be achieved for quantum systems. 
But first, some definitions.
\subsection{What is a Code?}
A code is a subset. 

If you have a system, classical quantum or other, which can assume states from some set, you can define any subset of these states to be a code.
The states in the code are called the \emph{codewords}.

Most of the time, we will also constrain our codes to be \emph{linear} with respect to some operation (usually denoted $+$), which means that for any codewords $a$ and $b$, $a + b$ is also a codeword. 
This is pretty common, and it means we can normally consider state sets which are vector spaces, and codes which are subspaces. 
This is true in both the classical and quantum case. 

A code can be used to fulfil a variety of purposes.
Compression, for example, involves codes whose codewords are shorter than the logical messages they represent.

We will mostly concern ourselves with \emph{error-correcting} codes, which can only be analysed using two other mathematical objects as tools.
The first of these is the \emph{error model}, the set of possible transformations which can act on a state (codeword or otherwise) without our knowledge. 
The second is the \emph{recovery map}, which takes as input states from the full set and outputs corresponding codewords. 
To solidify these ideas, let's consider an example.
\subsubsection{Example: 3-Bit Repetition Code}
Suppose Alice wants to tell Bob the value of a bit, $0$ or $1$, but that she has to use a channel which is subject to symmetric bit-flip:
\begin{figure}[!h]
\centering
\begin{tikzpicture}[x=3cm, y=2cm]
\node (in0) at (0, 1) {$0$};
\node (in1) at (0, 0) {$1$};
\node (out0) at (1, 1) {$0$};
\node (out1) at (1, 0) {$1$};
\draw [->] (in0.east) -- (out0.west) node [above,align=center,midway] {$1-p$};
\draw [->] (in0.east) -- (out1.west) node [above,align=center,pos=0.35] {$p$};
\draw [->] (in1.east) -- (out0.west) node [above,align=center,pos=0.65] {$p$};
\draw [->] (in1.east) -- (out1.west) node [below,align=center,midway] {$1-p$};
\end{tikzpicture}
\caption{Graphical representation of an error map on a classical bit which flips the bit (taking $0$ to $1$ and vice versa) with probability $p$.}
\end{figure}

Alice, then, would like to send messages from $\mathbb{Z}_2$, so she should design codes that have two codewords. 
Supposing that Alice has repeated access to the channel, and knows the probability $p$, she can design codes which use $\mathbb{Z}_2^n$ as the full state space. 
A simple thing that Alice can do is repeat herself three times (taking $n=3$) to make herself understood.
Bob, then, should infer that $0$ is the desired message when he receives a state containing mostly $0$s and $1$ when he receives a state containing mostly $1$s. 
Let's express these ideas mathematically, so that we can generalize later.

\begin{description}
\item[Codewords]: $000$, $111$
\item[Error Model]:
\begin{equation}
000 \mapsto \begin{array}{cl}
000 & (1-p)^3 \\ 001,\, 010,\, 100 & p(1-p)^2 \\ 110,\, 101,\, 011 & p^2(1-p) \\ 111 & p^3
\end{array} \quad 
111 \mapsto \begin{array}{cl}
111 & (1-p)^3 \\ 110,\, 101,\, 011 & p(1-p)^2 \\ 001,\, 010,\, 100 & p^2(1-p) \\ 000 & p^3
\end{array}
\end{equation} 
\item[Recovery Map]: $(000,\,001,\,010,\,100) \mapsto 000$, $(111,\,110,\,101,\,011) \mapsto 111$
\end{description}
We can see that, if there is a weight-two or weight-three error, Bob will infer the incorrect state.
The resulting probability of error is $3p^2(1-p) + p^3$. 

\textbf{Exercise: } When does this protocol amplify errors? How should we remedy this?

We will go on to construct quantum codes in later sections. 
But first, I should confess something.
\subsection{Fault Tolerance}
Let's begin with an overall reminder of what we're trying to accomplish.
We want to replicate the properties of TTL logic for quantum states and operations.
Not only are we able to interpret the output of a TTL gate using a perfect computer, we also know that TTL operations suppress errors that occur \emph{during the operations themselves}. 
We therefore have to \emph{encode operations} in some way, using a small subset of operations drawn from some large set to ensure that errors from the operations used to correct the code can themselves be corrected. 
For the first few examples, we won't focus on this, since it's useful to see that we can correct `vanilla' errors before moving on to attempt fault tolerance.

\section{Quantum Codes}
If fault tolerance wasn't a big enough problem, we have another one. 
Error models for quantum systems are much more complex than those for classical bits, because they're \emph{continuous}. They don't map $\ket{\psi}$ to $\ket{\psi_{\perp}}$, but instead to $U\ket{\psi}$ for $U$ some unknown unitary, for example.
There are even some channels for which no mixture of unitaries can describe the channel's effects. 
For this general set of quantum channels, we can represent their effects mathematically using a set of operators. 
This is frequently called the \emph{Kraus representation}, after Karl Kraus. 
Given these operators (let's call them $E_j$), we calculate the effect of the channel on a density matrix as follows:
\begin{equation}
\rho \mapsto \sum_j E_j \rho E_j \ct
\end{equation}
There's also a constraint on these operator sets.
In order to be valid transformations on quantum states, they have to map density matrices to density matrices.
Since density matrices are positive-semidefinite with trace one, the action of the operator set must be \emph{completely positive} (preserving positivity, even when it acts on \emph{part of a larger system}), and trace-preserving. 
This is true iff $\sum_j E_j \ct E_j = \id$.
Let's get this clearer with an example. 
Let's do bit-flip again, calling the channel $B$:
\begin{flalign}
B_0 = \sqrt{1 - p} \begin{bmatrix}
1 & 0 \\ 0 & 1
\end{bmatrix}, \quad B_1 = \sqrt{p} \begin{bmatrix}
0 & 1 \\ 1 & 0 
\end{bmatrix}
\end{flalign}
We can calculate the effect on a one-qubit density matrix with ground state population $q$ and coherence $c$:
\begin{flalign}
\rho &= \begin{bmatrix}
q & c \\ c^\ast & 1-q
\end{bmatrix} \\
\sum_j B_j \rho B_j \ct &= (1 - p) \rho + p X \rho X \\
&= (1 - p) \begin{bmatrix}
q & c \\ c^\ast & 1-q
\end{bmatrix}
 + p \begin{bmatrix}
   1-q & c^\ast \\c & q
\end{bmatrix} \\
&= \begin{bmatrix}
q + p - 2pq & c - p (c - c^\ast) \\
c^\ast - p (c^\ast - c) & 1 - p - q + 2pq
\end{bmatrix}
\end{flalign}
\textbf{Exercise: } Sub in the $\ket{0}$ and $\ket{1}$ states. What happens to them?

If we allow generic operations, this looks similar to the central problem of analog computing, that it's far easier to force an input from a continuous space to a few discrete values (oh, say, $0 \volts$ and $5 \volts$) than it is to force noisy values to stay close to the value that some arbitrary computation should be at ($x \volts$). 
For this reason, people with experience in analog computing are wary of quantum computing when they hear about it. 
All is not lost, though. 
In the next subsection, we'll see that these analog errors can be \emph{digitized}, but first, we have to define what it means to correct an error in the quantum case.
\subsection{The Knill-Laflamme Criterion and Noise Digitization}
To talk about which quantum errors can be detected or corrected, we should first make clear that in the typical case, not all of them can be corrected. 
To see this, consider the quantum bit-flip map defined above, and its action on the quantum bit-flip code $\ket{000},\,\ket{111}$.
With probability $p^3$, the channel maps one logical state directly to the other. 
Any sane recovery map would include $\ket{111} \mapsto \ket{111}$, so that there's always some probability of error. 
However, we can always try to take a subset of the operators $E_j$ and declare it to be exactly detectable or correctable. 
If our (assumed orthogonal) codewords are labeled $\ket{\psi_j}$, then this happens whenever
\begin{equation}
\elem{\psi_j}{E_k}{\psi_m} = C_{k} \delta_{jm} \textrm{ or } \elem{\psi_j}{E_k\ct E_l}{\psi_m} = C_{kl} \delta_{jm}
\end{equation}
Due to limited time, we won't go through the proof, but a detailed and accessible proof can be found in section 2.3 of Lidar and Brun. 
I would like to focus on the interpretation of this formula instead. 
First, let's note that it implies that any time two different codewords are acted upon by correctable Kraus operators, the resulting states will still be orthogonal. 
This means that, in theory, a recovery map can be designed which maps them back to the original code states, though this may be difficult in practice. 

Second, and more importantly, it implies that if a code can correct two Kraus operators $E_a$ and $E_b$, it can correct any linear combination of the two.
I will also not prove this, but it's in section 2.6 of Lidar/Brun.
If we can correct an $X$, $Y$ or $Z$ error on an arbitrary qubit, though, it follows that we can correct any single-qubit error, since $X$, $Y$, and $Z$ form a basis for the set of possible operators on one qubit.
It takes a little work to get such a code, we'll see some examples in the next section. 
\subsection{The Nine-Qubit Code}
First, let's make a note of what happens if a $Z$ error acts on the bit-flip code.
\begin{equation}
\alpha \ket{000} + \beta \ket{111} \mapsto \alpha \ket{000} - \beta \ket{111}. 
\end{equation}
This is the equivalent of a logical $Z$ operation, so this code cannot correct $Z$ errors. 
There is, however, a code which corrects $Z$ errors, it consists of the states $\ket{+++}$ and $\ket{---}$. When $Z$ acts on these states, they get mapped to $\ket{++-}$, et cetera, exactly as would happen if we acted $X$ on the states $\ket{000}$ and $\ket{111}$. Now is as good a time as any to put in some circuits for bit-flip, phase-flip and Shor encoding/decoding (from Chapter 2 of Lidar/Brun by Dave Bacon, used without permission$_{_\textsf{yolo}}$):
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{bacon_bf_repetition_circuit.png}
\caption{Typical circuit for an error correction scenario with only one noisy channel. In this case, the channel is a bit-flip, so we encode $\alpha \ket{0} + \beta \ket{1}$ into $\alpha \ket{000} + \beta \ket{111}$ for redundancy.}
\end{figure}

\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{bacon_pf_repetition_circuit.png}
\caption{Same deal as before, but with phase-flip, so we encode $\alpha \ket{0} + \beta \ket{1}$ into $\alpha \ket{+++} + \beta \ket{---}$ for redundancy. Bacon uses a $W$ for the Hadamard gate. Maybe this stands for Walsh, maybe not. We may never know \ldots}
\end{figure}
Given these two circuits, we can take a look at \emph{concatenation}, where we encode the logical qubits of one code into another code:
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{bacon_9bit_circuit.png}
\caption{Each physical bit of the three-qubit code versus phase flip is encoded into a three-qubit code versus bit-flip to construct a nine-qubit \emph{Shor code}.}
\end{figure}

\textbf{Exercise: } Show that this code can also correct a single $Y$ error on any qubit. 

Even though we get $Y$ error correction `for free' since it's the product of an $X$ and a $Z$, this is still a little clunky. In the next section, we take a look at a code which can correct an arbitrary single-qubit error using only five qubits.
\subsection{The Five-Qubit Code}
With the tools we have so far, we can't do much more than state the codewords of this code:
\begin{figure}[!h]
\centering
\includegraphics[width=0.5\textwidth]{five_qubit_codewords.png}
\caption{Some codewords, straight jacked from Nielsen/Chuang. I'm pretty sure this code was derived from some obscure research in codes over $GF(4)$, an abstract field that acts like the Paulis in some way.}
\end{figure}
\textbf{Exercise for Masochists: }Show that this code can correct an arbitrary single-qubit error using the Knill-Laflamme criteria.

The Shor code may have seemed clunky, but the fact that it could be decomposed into other codes meant we didn't really have to write out the codewords in the computational basis.
This is valuable, since there can be exponentially many terms in such a decomposition. 
This motivates the introduction of some new formalism, to make sure that the codes we study don't require us to write down an exponential number of parameters.
\section{The Stabilizer Formalism in a Nutshell}
There is at least one well-studied way to do this (there are a few others as well, but they're not as popular).
This theory uses sets of operators instead of basis vectors as its representation of a subspace, because tensor-product operators can give rise to states with non-trivial entanglement, which it turns out is necessary to do error correction [Prove this?].
This is the \emph{Heisenberg picture}. 

It's also best to use operators that form a group to do this, that way we don't have to keep track of any matrices during a calculation, we can just use the group operation. 
If we're bound and determined to use qubits at the physical level to store and process qubits at the logical level, we might as well use a group that has a matrix representation that's $2$-by-$2$, like the Pauli group. 
To write out tensor products of Paulis, we just put them in a string. 
These operators have $+1$ and $-1$ eigenspaces of equal size.
We can see this from the fact that each single-qubit Pauli has a $+1$ and a $-1$ eigenvalue, and that the eigenvalues of a tensor product of two matrices are the Cartesian product of the sets of eigenvalues of the original matrices.  
This means that, if we want to specify an $n-1$-qubit subspace of a space, we only have to write down one $n$-qubit operator, given as an $\mathcal{O}(n)$-letter string. 
This means that, in order to define a subspace with $k$ ``logical'' or ``effective'' qubits, 
we specify $n-k$ stabilisers, using a total of $\mathcal{O}(n^2)$ letters (assuming $k$ is constant with respect to $n$).
A rigourous expression of the codespace is as follows:
\begin{equation}
C(S) = \set{\ket{\psi} \suchthat s\ket{\psi}=\ket{\psi} \forall s \in S}
\end{equation}

\textbf{Exercise: }$-\id$ is a Pauli, but it can never be a stabiliser. Why not?

\textbf{Exercise: }In order for a list of $r$ Paulis to generate a stabiliser group with $n-r$ logical qubits, they have to commute and be independent under multiplication. Why?

It remains to be seen that subspaces defined in this way can detect/correct errors, though it is sufficient to detect/correct Pauli errors.
Let's show that Pauli errors can be detected if they anticommute with some stabiliser.

First, let's note that, for stabiliser codes, logicals commute with the stabiliser, but are not part of it:
\begin{equation}
L\ket{\psi} = \ket{\phi}, \,\, \ket{\phi},\, \ket{\psi} \in C(S), \, \ket{\phi} \neq{\ket{\psi}} \\
\end{equation}
\begin{flalign}
s\ket{\phi} &= \ket{\phi} \forall s \\
\therefore sL\ket{\psi} &= L\ket{\psi} \forall s \\
\therefore sL\ket{\psi} &= Ls\ket{\psi} \forall s
\end{flalign}
Since Paulis either commute or anticommute, this means that $\com{s}{L}=0 \forall s$. 

An error is undetectable when it can change $\braket{\psi}{\phi}$, this is exactly what logicals do. 
Given Pauli errors, the product has to be a logical for the error to not be correctable. 
Let's go for an example of errors which are detectable but not correctable for the $5$-qubit code.
\subsection{CSS codes}
These are like easy stabiliser codes.
\subsection{Homological Codes}
These are like easy CSS codes.
\subsection{The Surface Code}
This is like an easy homological code.
\section{What I Haven't Covered}
\begin{description}
\item[How To Encode A Qubit in Your Experiment]: You might have a large spin system, many-level transmon, trapped ion or some other exotic Hilbert space in your laboratory.
It comes with its own set of noise maps and its own allowed operations at the physical level (maybe these form a universal gate set, maybe not).
What's the best way to encode a qubit into it?
Nobody really knows. 
Most of the time, we make some arbitrary decision, like picking two low-energy levels. 
It would be interesting to pursue this, though. 
\end{description}
\end{document}